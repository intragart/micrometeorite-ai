{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf # for modell training\n",
    "import math\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt # to show graphical results\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# own modules\n",
    "import modules.config as config\n",
    "from modules.ai_dataset import ai_dataset\n",
    "from modules.export_trained_model import export_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training and testing data into one class object\n",
    "raw_data = ai_dataset(config.TRAINING_DATA)\n",
    "#raw_data.load_data(config.TEST_DATA)\n",
    "raw_data.resize(config.IMG_SIZE)\n",
    "raw_data.shuffle()\n",
    "raw_data.tf_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-creation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of optimizers\n",
    "optimizers = [\"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"ftrl\", \"nadam\", \"rmsprop\", \"sgd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the raw data into training and test data\n",
    "split_index = math.ceil(len(raw_data.get_tf_images()) * (1-config.PERCENT_TEST))\n",
    "\n",
    "training_images = raw_data.get_tf_images()[0:split_index]\n",
    "training_labels = raw_data.get_tf_labels()[0:split_index]\n",
    "\n",
    "test_images = raw_data.get_tf_images()[split_index:]\n",
    "test_labels = raw_data.get_tf_labels()[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-detroit",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train a model on each optimizer\n",
    "for optim in optimizers:\n",
    "\n",
    "    reset_keras()\n",
    "\n",
    "    # print current optimizer\n",
    "    print(\"Current Optimizer: \"+optim)\n",
    "\n",
    "    model = tf.keras.models.Sequential(name=optim)\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding=\"valid\", activation=\"relu\", input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(4096, activation=\"relu\", bias_initializer=\"random_normal\"))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation=\"relu\", bias_initializer=\"random_normal\"))\n",
    "    model.add(tf.keras.layers.Dense(raw_data.get_labels_count(), activation=\"softmax\", bias_initializer=\"random_normal\"))\n",
    "\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optim,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(training_images, training_labels, epochs=config.TRAINING_EPOCHS,\n",
    "              validation_data=(test_images, test_labels))\n",
    "\n",
    "    # Plot learning curve\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(history.history[\"accuracy\"], label = \"accuracy\", color = \"k\", linestyle = \"solid\")\n",
    "    ax1.plot(history.history[\"val_accuracy\"], label = \"val_accuracy\", color = \"k\", linestyle = \"dotted\")\n",
    "    ax2.plot(history.history[\"loss\"], label = \"loss\", color = \"k\", linestyle = \"dashed\")\n",
    "    ax2.plot(history.history[\"val_loss\"], label = \"val_loss\", color = \"k\", linestyle = \"dashdot\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    fig.legend()\n",
    "    ax1.set_title(\"Optimizer:\"+optim)\n",
    "\n",
    "    # evaluate model\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "    # export the trained model\n",
    "    export_trained_model(model, config.TRAINING_EPOCHS, test_loss, test_acc, history, fig, raw_data, config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-cinema",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export test images for predictions\n",
    "if False:\n",
    "    if not os.path.exists(config.MODEL_PATH+\"/val_img\"):\n",
    "        os.makedirs(config.MODEL_PATH+\"/val_img\", exist_ok=True)\n",
    "\n",
    "    for i in range(split_index, len(raw_data.get_tf_images())):\n",
    "        cv.imwrite(config.MODEL_PATH+\"/val_img/\"+str(i)+\"_\"+raw_data.get_label(i)+\".png\",raw_data.get_image(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if False:\n",
    "        time.sleep(60)\n",
    "        os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
