{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import libraries\r\n",
    "import os\r\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\r\n",
    "import tensorflow as tf # for modell training\r\n",
    "import keras_tuner as kt\r\n",
    "import matplotlib.pyplot as plt # to show graphical results\r\n",
    "from matplotlib.ticker import MaxNLocator\r\n",
    "from datetime import datetime\r\n",
    "import cv2\r\n",
    "import math\r\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# own modules\r\n",
    "import modules.config as config\r\n",
    "from modules.ai_dataset import ai_dataset\r\n",
    "from modules.export_trained_model import export_trained_model\r\n",
    "from modules.conf_matrix import conf_matrix\r\n",
    "from modules.roc import roc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import data\r\n",
    "raw_data = ai_dataset(config.TRAINING_DATA, config.IMG_SIZE, True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# split the raw data into training and test data\r\n",
    "split_index = math.ceil(len(raw_data.get_tf_images()) * (1-config.PERCENT_TEST))\r\n",
    "\r\n",
    "training_images = raw_data.get_tf_images()[0:split_index]\r\n",
    "training_labels = raw_data.get_tf_labels()[0:split_index]\r\n",
    "\r\n",
    "test_images = raw_data.get_tf_images()[split_index:]\r\n",
    "test_labels = raw_data.get_tf_labels()[split_index:]\r\n",
    "\r\n",
    "print(\"tensor shape:\", raw_data.get_tf_images().get_shape())\r\n",
    "print(\"training images:\", len(training_images))\r\n",
    "print(\"validation images:\", len(test_images))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# show an image from the training data\r\n",
    "plt.figure()\r\n",
    "plt.imshow(cv2.cvtColor(raw_data.get_image(0), cv2.COLOR_BGR2RGB))\r\n",
    "plt.colorbar()\r\n",
    "plt.grid(False)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# verify preperation\r\n",
    "plt.figure(figsize=(10,10))\r\n",
    "for i in range(25):\r\n",
    "    plt.subplot(5,5,i+1)\r\n",
    "    plt.xticks([])\r\n",
    "    plt.yticks([])\r\n",
    "    plt.grid(False)\r\n",
    "    plt.imshow(cv2.cvtColor(raw_data.get_image(i), cv2.COLOR_BGR2RGB))\r\n",
    "    plt.xlabel(raw_data.get_label(i), color=\"blue\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# debug - show available hardware for tf.keras\r\n",
    "tf.config.list_physical_devices()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# list of optimizers\r\n",
    "optimizers = [\"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"ftrl\", \"nadam\", \"rmsprop\", \"sgd\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the convolutional base\r\n",
    "# https://www.mydatahack.com/building-alexnet-with-keras/\r\n",
    "def build_model(hp):\r\n",
    "\r\n",
    "    optim = \"adadelta\"\r\n",
    "    #optim = \"adagrad\"\r\n",
    "    #optim = \"adam\"\r\n",
    "    #optim = \"rmsprop\"\r\n",
    "\r\n",
    "    if optim == \"adadelta\":\r\n",
    "        opt = tf.keras.optimizers.Adadelta(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]))\r\n",
    "    elif optim == \"adagrad\":\r\n",
    "        opt = tf.keras.optimizers.Adagrad(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]))\r\n",
    "    elif optim == \"adam\":\r\n",
    "        opt = tf.keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]))\r\n",
    "    elif optim == \"rmsprop\":\r\n",
    "        opt = tf.keras.optimizers.RMSprop(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]))\r\n",
    "    else:\r\n",
    "        return 0\r\n",
    "\r\n",
    "    model = tf.keras.models.Sequential(name=f\"bo-{optim}\")\r\n",
    "\r\n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding=\"valid\", activation=\"relu\", input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)))\r\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\r\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding=\"same\", activation=\"relu\"))\r\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\r\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\r\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\r\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\r\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\r\n",
    "\r\n",
    "    model.add(tf.keras.layers.Flatten())\r\n",
    "\r\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int(\"Dense_01\", min_value=2048, max_value=8192, step=1024), activation=\"relu\", bias_initializer=\"random_normal\"))\r\n",
    "    model.add(tf.keras.layers.Dropout(rate=hp.Float(\"Dropout_01\", min_value=0.0, max_value=0.8, step=0.05)))\r\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int(\"Dense_02\", min_value=2048, max_value=8192, step=1024), activation=\"relu\", bias_initializer=\"random_normal\"))\r\n",
    "    model.add(tf.keras.layers.Dropout(rate=hp.Float(\"Dropout_02\", min_value=0.0, max_value=0.8, step=0.05)))\r\n",
    "    model.add(tf.keras.layers.Dense(units=2, activation=\"softmax\", bias_initializer=\"random_normal\"))\r\n",
    "\r\n",
    "    # Compile the model\r\n",
    "    model.compile(\r\n",
    "        optimizer=opt,\r\n",
    "        loss=\"sparse_categorical_crossentropy\",\r\n",
    "        metrics=[\"accuracy\"]\r\n",
    "    )\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tuner = kt.BayesianOptimization(\r\n",
    "    build_model,\r\n",
    "    objective=\"val_accuracy\",\r\n",
    "    max_trials=100, # number of different configurations\r\n",
    "    executions_per_trial=3, # number of trainings per configuration\r\n",
    "    overwrite=True, # ignore previous results\r\n",
    "    directory=config.MODEL_PATH,\r\n",
    "    project_name=f\"bo_{datetime.now().strftime('%y%m%d%H%M')}\"\r\n",
    ")\r\n",
    "\r\n",
    "tuner.search_space_summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exec_times = [datetime.now()]\r\n",
    "print(\"Start:\", exec_times[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# start the search for the best hyperparameters\r\n",
    "tuner.search(training_images, training_labels, epochs=config.TRAINING_EPOCHS, \r\n",
    "            validation_data=(test_images, test_labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tuner.results_summary(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get best model\r\n",
    "model = tuner.get_best_models(num_models=1)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train the model\r\n",
    "history = model.fit(training_images, training_labels, epochs=config.TRAINING_EPOCHS, \r\n",
    "                    validation_data=(test_images, test_labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# evaluate model\r\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\r\n",
    "print(\"validated accuracy:\", f\"{test_acc:.4f}\")\r\n",
    "print(\"validated loss:\", f\"{test_loss:.4f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exec_times.append(datetime.now())\r\n",
    "print(\"Stop:\", exec_times[1])\r\n",
    "print(\"Elapsed9:\", exec_times[1] - exec_times[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot learning curve\r\n",
    "fig_hist = plt.figure()\r\n",
    "ax1 = fig_hist.add_subplot()\r\n",
    "ax2 = ax1.twinx()\r\n",
    "ax1.set_title(f\"model: {model.name}\")\r\n",
    "ax1.plot(history.history[\"accuracy\"], label = \"accuracy\", color = \"k\", linestyle=\"-\")\r\n",
    "ax1.plot(history.history[\"val_accuracy\"], label = \"val_accuracy\", color = \"k\", linestyle=\"--\")\r\n",
    "ax2.plot(history.history[\"loss\"], label = \"loss\", color = \"r\", linestyle=\"-\")\r\n",
    "ax2.plot(history.history[\"val_loss\"], label = \"val_loss\", color = \"r\", linestyle=\"--\")\r\n",
    "ax1.set_xlabel(\"epoch\",)\r\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
    "ax1.set_ylabel(\"accuracy\",)\r\n",
    "ax2.set_ylabel(\"loss\",)\r\n",
    "fig_hist.legend(bbox_to_anchor=(1.22,0.8), loc=\"center right\", ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_labels_for_dataframe = []\r\n",
    "\r\n",
    "for i in test_labels:\r\n",
    "    if int(i) == 0:\r\n",
    "        # 'Nicht-Mikrometeorit' , 'Mikrometeorit'\r\n",
    "        test_labels_for_dataframe.append([1, 0])\r\n",
    "    else:\r\n",
    "        # 'Nicht-Mikrometeorit' , 'Mikrometeorit'\r\n",
    "        test_labels_for_dataframe.append([0, 1])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create confusion matrix\r\n",
    "cm, ekm = conf_matrix(model, test_images, test_labels_for_dataframe)\r\n",
    "print(\"TPR: \", ekm[\"TPR\"], \" FPR: \", ekm[\"FPR\"], \" Precision: \", ekm[\"Precision\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# roc\r\n",
    "roc_plt = roc(model, test_images, test_labels_for_dataframe)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_trained_model(model, config.TRAINING_EPOCHS, test_loss, test_acc, history, fig_hist, cm, ekm, roc_plt, exec_times, raw_data, config.MODEL_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if False:\r\n",
    "    time.sleep(60)\r\n",
    "    os.system('shutdown -s')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8954a5446874c3e6dcca595665836a5a80634449647eb64bcab4af3ac6b40681"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}