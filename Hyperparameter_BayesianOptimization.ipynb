{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import tensorflow as tf # for modell training\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt # to show graphical results\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# own modules\n",
    "import modules.config as config\n",
    "from modules.ai_dataset import ai_dataset\n",
    "from modules.export_trained_model import export_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "raw_data = ai_dataset(config.TRAINING_DATA, config.IMG_SIZE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the raw data into training and test data\n",
    "split_index = math.ceil(len(raw_data.get_tf_images()) * (1-config.PERCENT_TEST))\n",
    "\n",
    "training_images = raw_data.get_tf_images()[0:split_index]\n",
    "training_labels = raw_data.get_tf_labels()[0:split_index]\n",
    "\n",
    "test_images = raw_data.get_tf_images()[split_index:]\n",
    "test_labels = raw_data.get_tf_labels()[split_index:]\n",
    "\n",
    "print(\"tensor shape:\", raw_data.get_tf_images().get_shape())\n",
    "print(\"training images:\", len(training_images))\n",
    "print(\"validation images:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show an image from the training data\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(raw_data.get_image(0), cv2.COLOR_BGR2RGB))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify preperation\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cv2.cvtColor(raw_data.get_image(i), cv2.COLOR_BGR2RGB))\n",
    "    plt.xlabel(raw_data.get_label(i), color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug - show available hardware for tf.keras\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of optimizers\n",
    "optimizers = [\"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"ftrl\", \"nadam\", \"rmsprop\", \"sgd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the convolutional base\n",
    "# https://www.mydatahack.com/building-alexnet-with-keras/\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential(name=\"bo-adadelta\")\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding=\"valid\", activation=\"relu\", input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"valid\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int(\"Dense_01\", min_value=2048, max_value=8192, step=1024), activation=\"relu\", bias_initializer=\"random_normal\"))\n",
    "    model.add(tf.keras.layers.Dropout(rate=hp.Float(\"Dropout_01\", min_value=0.0, max_value=0.8, step=0.05)))\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int(\"Dense_02\", min_value=2048, max_value=8192, step=1024), activation=\"relu\", bias_initializer=\"random_normal\"))\n",
    "    model.add(tf.keras.layers.Dropout(rate=hp.Float(\"Dropout_02\", min_value=0.0, max_value=0.8, step=0.05)))\n",
    "    model.add(tf.keras.layers.Dense(units=2, activation=\"softmax\", bias_initializer=\"random_normal\"))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adadelta(\n",
    "            hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100, # number of different configurations\n",
    "    executions_per_trial=3, # number of trainings per configuration\n",
    "    overwrite=True, # ignore previous results\n",
    "    directory=config.MODEL_PATH,\n",
    "    project_name=\"bo_adadelta_02\"\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start:\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the search for the best hyperparameters\n",
    "tuner.search(training_images, training_labels, epochs=config.TRAINING_EPOCHS, \n",
    "            validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model\n",
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit(training_images, training_labels, epochs=config.TRAINING_EPOCHS, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"validated accuracy:\", f\"{test_acc:.4f}\")\n",
    "print(\"validated loss:\", f\"{test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "ax1 = fig.add_subplot()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.set_title(f\"model: {model.name}\", size=16)\n",
    "ax1.plot(history.history[\"accuracy\"], label = \"accuracy\", color = \"k\", linestyle=\"-\")\n",
    "ax1.plot(history.history[\"val_accuracy\"], label = \"val_accuracy\", color = \"k\", linestyle=\"--\")\n",
    "ax2.plot(history.history[\"loss\"], label = \"loss\", color = \"r\", linestyle=\"-\")\n",
    "ax2.plot(history.history[\"val_loss\"], label = \"val_loss\", color = \"r\", linestyle=\"--\")\n",
    "ax1.set_xlabel(\"epoch\", size=13)\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax1.set_ylabel(\"accuracy\", size=13)\n",
    "ax2.set_ylabel(\"loss\", size=13)\n",
    "#fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1., 0., 0.), ncol=4)\n",
    "fig.legend(bbox_to_anchor=(0.5,-0.2), loc=\"lower center\", ncol=4, prop={\"size\":13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.set_title(f\"model: {model.name}\")\n",
    "ax1.plot(history.history[\"accuracy\"], label = \"accuracy\", color = \"k\", linestyle=\"-\")\n",
    "ax1.plot(history.history[\"val_accuracy\"], label = \"val_accuracy\", color = \"k\", linestyle=\"--\")\n",
    "ax2.plot(history.history[\"loss\"], label = \"loss\", color = \"r\", linestyle=\"-\")\n",
    "ax2.plot(history.history[\"val_loss\"], label = \"val_loss\", color = \"r\", linestyle=\"--\")\n",
    "ax1.set_xlabel(\"epoch\",)\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax1.set_ylabel(\"accuracy\",)\n",
    "ax2.set_ylabel(\"loss\",)\n",
    "fig.legend(bbox_to_anchor=(1.22,0.8), loc=\"center right\", ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_trained_model(model, config.TRAINING_EPOCHS, test_loss, test_acc, history, fig, raw_data, config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    time.sleep(60)\n",
    "    os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8954a5446874c3e6dcca595665836a5a80634449647eb64bcab4af3ac6b40681"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
