{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt # to show graphical results\r\n",
    "import re\r\n",
    "import os\r\n",
    "import tempfile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# own modules\r\n",
    "import modules.config as config\r\n",
    "from modules.load_model import load_model\r\n",
    "from modules.load_predict_data import load_predict_data\r\n",
    "from prepare_images import prepare_images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get model name\r\n",
    "MODEL_NAME = re.search(r\"\\/([A-Za-z0-9_-]{1,})\\.zip\", config.TRAINED_MODEL)\r\n",
    "print(\"Current Model:\", MODEL_NAME.group(1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import pretrained model\r\n",
    "model, label, tensorshape = load_model(config.TRAINED_MODEL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# show path to file(s) to be predicted\r\n",
    "print(\"Prediction Source Path:\", config.PREDICT_DATA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If true, prediction pictures are being preprocessed (white background, 1:1 format, cutout)\r\n",
    "# !! Contour Model needed, please see README.md !!\r\n",
    "preprocessing = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load data to be predicted\r\n",
    "# predict_me -- contains the images to be predicted (as tf.stack)\r\n",
    "# predict_file -- contains the images to be predicted (raw or preprocessed)\r\n",
    "# predict_file_name -- name of the original file\r\n",
    "predict_me = []\r\n",
    "predict_file = []\r\n",
    "predict_file_name = []\r\n",
    "\r\n",
    "if preprocessing == True:\r\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\r\n",
    "        print(tmpdir)\r\n",
    "        prepare_images(config.PREDICT_DATA, tmpdir)\r\n",
    "        predict_me, predict_file, predict_file_name = load_predict_data(tmpdir, tensorshape[1], tensorshape[2])\r\n",
    "else:\r\n",
    "    predict_me, predict_file, predict_file_name = load_predict_data(config.PREDICT_DATA, tensorshape[1], tensorshape[2])\r\n",
    "print(\"Pictures:\", len(predict_me))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load pretrained model as probability model\r\n",
    "prob_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make predictions\r\n",
    "predictions = prob_model.predict(predict_me)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print the prediction results for each picture\r\n",
    "for i in range(len(predict_file_name)):\r\n",
    "    print(\"Filename:\", predict_file_name[i])\r\n",
    "\r\n",
    "    for key in label.keys():\r\n",
    "        print(f\"  - {key}: {predictions[i][label[key]]}\")\r\n",
    "\r\n",
    "    print(\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create export path if given\r\n",
    "if config.PREDICT_RESULTS != \"\":\r\n",
    "    if not os.path.exists(os.path.join(config.PREDICT_RESULTS,MODEL_NAME.group(1))):\r\n",
    "        os.makedirs(os.path.join(config.PREDICT_RESULTS,MODEL_NAME.group(1)), exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export the prediction results for each picture into a file\r\n",
    "if config.PREDICT_RESULTS != \"\":\r\n",
    "    with open(f\"{config.PREDICT_RESULTS}/{MODEL_NAME.group(1)}/results.txt\", \"w\") as file:\r\n",
    "        for i in range(len(predict_file_name)):\r\n",
    "            file.write(f\"Filename: {predict_file_name[i]}\\n\")\r\n",
    "\r\n",
    "            for key in label.keys():\r\n",
    "                file.write(f\"  - {key}: {predictions[i][label[key]]}\\n\")\r\n",
    "\r\n",
    "            file.write(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(len(predict_me)):\r\n",
    "    current_prediction = list(label.keys())[list(label.values()).index(predictions[i].argmax())]\r\n",
    "\r\n",
    "    fig = plt.figure(figsize=(6, 8), facecolor=\"white\")    \r\n",
    "    fig.suptitle(f\"Prediction {i+1}: {current_prediction}\\n\")\r\n",
    "    fig.text(0.1, 0.93, f\"Model: {MODEL_NAME.group(1)}\")\r\n",
    "    fig.text(0.1, 0.91, f\"File: {predict_file_name[i]}\")\r\n",
    "    \r\n",
    "    pic = fig.add_subplot(2,1,1)\r\n",
    "    pic.axes.xaxis.set_ticks([])\r\n",
    "    pic.axes.yaxis.set_ticks([])\r\n",
    "    pic.imshow(predict_file[i])\r\n",
    "    \r\n",
    "    colrs = []\r\n",
    "    for j in range(len(label)):\r\n",
    "        if j == predictions[i].argmax():\r\n",
    "            colrs.append(\"#DF2020\")\r\n",
    "        else:\r\n",
    "            colrs.append(\"grey\")\r\n",
    "    \r\n",
    "    hist = fig.add_subplot(2,1,2)\r\n",
    "    hist.bar(list(label.keys()), predictions[i], color=colrs)\r\n",
    "    hist.set_ylabel(\"Confidence\")\r\n",
    "    hist.set_ylim([0,1])\r\n",
    "\r\n",
    "    if config.PREDICT_RESULTS != \"\":\r\n",
    "        fig.savefig(f\"{config.PREDICT_RESULTS}/{MODEL_NAME.group(1)}/pred_{predict_file_name[i]}_{current_prediction}.png\", dpi=100, transparent=False, facecolor=\"w\")\r\n",
    "    else:\r\n",
    "        fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "8954a5446874c3e6dcca595665836a5a80634449647eb64bcab4af3ac6b40681"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}